JobClient

用户同MapReduce集群交互的接口，用于提交作业、跟踪作业状态、访问作业日志与获得MapReduce集群状态信息等。


JobStatus[]	JobClient.getAllJobs() 
获取集群中已提交的全部作业
JobStatus[]  JobStatus数组中每一成员对应已提交的每一作业的状态

TaskReport[]	JobClient.getMapTaskReports(JobID jobId) 
根据MapMap作业ID，获得map任务状态报告
JobID MapReduce作业ID
TaskReport[]  TaskReport数组，数组中每一成员代表指示的map任务的状态






TaskReport[]	JobClient.getReduceTaskReports(JobID jobId) 
根据MapReduce作业ID，获得reduce任务状态报告
JobID MapReduce作业ID
 TaskReport[]  TaskReport数组，数组中每一成员代表指示的reduce任务的状态





RunningJob	JobClient.submitJob(String jobFile) 
提交作业给MapReduce系统
String 标识MapReduce作业文件名
RunningJob 返回用于标识MapReduce作业的对象




package org.myorg;
import java.io.IOException;
import java.util.*;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapred.*;
import org.apache.hadoop.util.*;
public class WordCount {

public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> {
private final static IntWritable one = new IntWritable(1);
private Text word = new Text();

public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {
String line = value.toString();
StringTokenizer tokenizer = new StringTokenizer(line);
while (tokenizer.hasMoreTokens()) {
word.set(tokenizer.nextToken());
output.collect(word, one);
}
}
}

public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> {
public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {
int sum = 0;
while (values.hasNext()) {
sum += values.next().get();
}
output.collect(key, new IntWritable(sum));
}
}

public static void main(String[] args) throws Exception {
JobConf conf = new JobConf(WordCount.class);
conf.setJobName("wordcount");

 conf.setOutputKeyClass(Text.class);
  conf.setOutputValueClass(IntWritable.class);
 conf.setMapperClass(Map.class);
    conf.setCombinerClass(Reduce.class);
	      conf.setReducerClass(Reduce.class);
      conf.setInputFormat(TextInputFormat.class);
	      conf.setOutputFormat(TextOutputFormat.class);
	
   FileInputFormat.setInputPaths(conf, new Path(args[0]));
      FileOutputFormat.setOutputPath(conf, new Path(args[1]));
	      JobClient.runJob(conf);
	    }
}
	


（1）EagerTaskInitializationListener维护了若干个工作线程（数目由“mapred.jobinit.threads”配置，默认为4），它指派其中一个工作线程负责Job的初始化工作。
     工作线程使用InputFormat接口（见MapReduce产品外部接口）获取JobClient提交的InputSplits信息，并为每一InputSplit创建一个对应的Map任务。在MapTask中，记载了该MapTask的InputSplit信息，这为之后的任务分配做好了准备（InputSplit记载了Map任务的位置信息，网络被视作树状拓扑结构，每个运行TaskTracker的机器都对应到树的叶子节点上，而非叶子节点就是连接它们的交换机。每个Map任务就挂在其所属叶子节点及其祖先节点上。当分派任务时，就可从TaskTracker对应叶子节点出发，逐步向上，从而找到一个距离该TaskTracker距离最近的且尚未分派出去的Map任务）。
    根据Job配置信息“mapred.reduce.tasks”，创建若干个Reduce任务，并额外创建两个Cleanup任务和两个Setup任务（各以Map任务或Reduce任务的身份被分派，将占用Map/Reduce的Slot），用于执行OutputFormat接口中的操作（见MapReduce产品外部接口）。



(2)当TaskTracker通过心跳向JobTracker报告它需要分配任务时，JobTracker尝试向TaskTracker分派任务，JobTracker会优先进行Setup和Cleanup任务（mapJobSetup,mapTaskCleanup，mapJobCleanup，reduceJobSetup,reduceTaskCleanup，reduceJobCleanup）的分派，如果找不到这些类型任务，则从JobQueueTaskScheduler那里获得任务。
     JobQueueTaskScheduler首先顺序遍历JobQueueJobInProgressListener.jobQueue中的每一个处于RUNNING状态的Job（已按优先级与启动时间排好序，jobQueue中可能有PREP状态的Job，它们尚未被EagerTaskInitListener初始化），尝试从中分派任务。每次从一个Job中分派Map任务时，遵序如下步骤：（a）优先分派执行失败后等待重试的任务，对于这些需要重试的任务，并不考虑其位置信息；（b）对从未分派的Map任务，如果TaskTracker与其InptuSplit相近，则分配之；（c）对从未分派的Map任务，如果TaskTracker与其InptuSplit距离较远（非Data-Local，非Rack-Local），则一次心跳只能分配给TaskTracker一个Map任务。Reduce任务的分配不需要考虑位置信息，但一次心跳最多只给TaskTracker分配一个Reduce任务。



listener.jobAdded(job);
public  {

void jobAdded(JobInProgress job)

将作业添加至EagerTaskInitListener维护的作业队列中
JobInProgress 代表用户提交的Map/Reduce作业


void EagerTaskInitListener.jobAdded
